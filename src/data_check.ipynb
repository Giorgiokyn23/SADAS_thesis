{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if edges are valid (i.e. they are from and to existing nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input folder\n",
    "input_folder = \"../data/my_datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_edges(dataset, id_str, ori_str, dest_str):\n",
    "    # load nodes\n",
    "    print(\"Loading nodes...\")\n",
    "    nodes = pd.read_csv(input_folder+dataset+\"_nodes.csv\", sep=';', dtype=pd.StringDtype())\n",
    "    # create set of ids of the nodes\n",
    "    #nodes_ids = nodes[[id_str]]\n",
    "    ids_set = set(nodes[id_str].unique())#without header\n",
    "    #print(ids_set)\n",
    "    print(\"Loading edges...\")\n",
    "    # load edges\n",
    "    edges = pd.read_csv(input_folder+dataset+\"_edges.csv\", sep=';', dtype=pd.StringDtype())\n",
    "    edges_ids = edges[[ori_str, dest_str]]\n",
    "    invalid_edges = []\n",
    "    with tqdm(total=len(list(edges_ids.iterrows()))) as pbar:\n",
    "        for index, edg in edges_ids.iterrows():\n",
    "            pbar.update(1)\n",
    "            if edg[ori_str] not in ids_set:\n",
    "                invalid_edges.append(edg[ori_str])\n",
    "            if edg[dest_str] not in ids_set:\n",
    "                invalid_edges.append(edg[dest_str])\n",
    "    print(\"Invalid edges for {}: {}\".format(dataset, invalid_edges))\n",
    "    return invalid_edges\n",
    "        \n",
    "##The invalid edge in AUI is (190647, 52155)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1281116/1281116 [01:52<00:00, 11401.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid edges for AUI: ['0000000000190647']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1674271/1674271 [02:27<00:00, 11332.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid edges for CTP: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1524509/1524509 [02:13<00:00, 11387.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid edges for NEXI: []\n"
     ]
    }
   ],
   "source": [
    "tmp = check_edges(\"AUI\", \"NDG\", \"NDG_ORIGINE\", \"NDG_DESTINAZIONE\")\n",
    "tmp = check_edges(\"CTP\", \"CD_NDG\", \"ID_NODO_ORIGINE\", \"ID_NODO_DESTINAZIONE\")\n",
    "tmp = check_edges(\"NEXI\", \"ID_NODO\", \"ID_NODO_ORIGINE\", \"ID_NODO_DESTINAZIONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check which datasets are multigraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input folder\n",
    "input_folder = \"../data/my_datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_multigraph(dataset, ori_str, dest_str):\n",
    "    # load edges in ram\n",
    "    edges = pd.read_csv(input_folder+dataset+\"_edges.csv\", sep=';', dtype=pd.StringDtype())\n",
    "    # keep only columns containing origin and destination ids\n",
    "    only_ids = edges[[ori_str, dest_str]]\n",
    "    num_edges = len(only_ids)\n",
    "    unique_edges = only_ids.drop_duplicates()\n",
    "    num_unique_edges = len(unique_edges)\n",
    "    if num_unique_edges < num_edges:\n",
    "        print(\"{}: total number {} vs unique edges {}\".format(dataset, num_edges, num_unique_edges))\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUI: total number 1281116 vs unique edges 247321\n",
      "CTP: total number 1674271 vs unique edges 1519361\n",
      "NEXI: total number 1524509 vs unique edges 873433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = is_multigraph(\"AUI\", \"NDG_ORIGINE\", \"NDG_DESTINAZIONE\")\n",
    "tmp = is_multigraph(\"CTP\", \"ID_NODO_ORIGINE\", \"ID_NODO_DESTINAZIONE\")\n",
    "tmp = is_multigraph(\"NEXI\", \"ID_NODO_ORIGINE\", \"ID_NODO_DESTINAZIONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create subgraphs for faster tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input and output folders\n",
    "input_folder =\"../data/my_datasets/\"\n",
    "output_folder=\"../data/my_datasets/small/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_subgraph(dataset, id_name, id_ori_name, id_dest_name, num_lines):\n",
    "    print(\"Creating \"+ dataset + \" subgraph of {} nodes\".format(num_lines))\n",
    "    #Load nodes\n",
    "    nodes = pd.read_csv(input_folder+dataset+\"_nodes.csv\", sep=';', dtype=pd.StringDtype())\n",
    "    #Sort descending\n",
    "    #sorted_nodes = nodes.sort_values(by=id_name, ascending=False)\n",
    "    #Store the first num_lines rows in new csv\n",
    "    nodes.head(num_lines).to_csv(output_folder+dataset+\"_nodes.csv\", sep=';', index=False)\n",
    "    #Creating list of UNIQUE NDGS of the first num_lines rows\n",
    "    nodes_ids = nodes.head(num_lines)[id_name].tolist()\n",
    "\n",
    "    #Load edges\n",
    "    edges = pd.read_csv(input_folder+dataset+\"_edges.csv\", sep=';', dtype=pd.StringDtype())\n",
    "    #Select rows from existing nodes\n",
    "    from_existing = edges[edges[id_ori_name].isin(nodes_ids)]\n",
    "    #Filter those and take only the edges to existing nodes\n",
    "    to_existing = from_existing[from_existing[id_dest_name].isin(nodes_ids)]\n",
    "    #Store the edges\n",
    "    edg_name = output_folder+dataset+\"_edges.csv\"\n",
    "    to_existing.to_csv(edg_name, sep=';', index=False)\n",
    "    #os.system(\"wc -l \"+ edg_name + \" | cut -f1 -d' '\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating AUI subgraph of 200 nodes\n",
      "Creating CTP subgraph of 500 nodes\n",
      "Creating NEXI subgraph of 40000 nodes\n"
     ]
    }
   ],
   "source": [
    "# Delete all files from output folder\n",
    "os.system(\"rm \"+output_folder+\"*.csv\")\n",
    "# Create AUI subgraph of n_nodes nodes\n",
    "n_nodes = 200\n",
    "make_subgraph(\"AUI\", \"NDG\", \"NDG_ORIGINE\", \"NDG_DESTINAZIONE\", n_nodes)\n",
    "# Create CTP subgraph of n_nodes nodes\n",
    "n_nodes = 500\n",
    "make_subgraph(\"CTP\", \"CD_NDG\", \"ID_NODO_ORIGINE\", \"ID_NODO_DESTINAZIONE\", n_nodes)\n",
    "# Create NEXI subgraph of n_nodes nodes\n",
    "n_nodes = 40000\n",
    "make_subgraph(\"NEXI\", \"ID_NODO\", \"ID_NODO_ORIGINE\", \"ID_NODO_DESTINAZIONE\", n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
